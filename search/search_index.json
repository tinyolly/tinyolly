{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"The World's First Desktop Observability Platform"},{"location":"#introducing-tinyolly","title":"Introducing TinyOlly","text":"<p>Repository: https://github.com/tinyolly/tinyolly</p> <pre><code>git clone https://github.com/tinyolly/tinyolly\n</code></pre>"},{"location":"#why-tinyolly","title":"Why TinyOlly?","text":"<p>Why send telemetry to a cloud observability platform while coding? Why not have one on your desktop?</p> <p>TinyOlly is a lightweight OpenTelemetry-native observability platform built from scratch to visualize and correlate logs, metrics, and traces. No 3rd party observability tools - just Python (FastAPI), Redis, OpenAPI, and JavaScript.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Development-focused - Perfect your app's telemetry locally before production</li> <li>Full OpenTelemetry support - Native OTLP ingestion (gRPC &amp; HTTP)</li> <li>Trace correlation - Link logs, metrics, and traces automatically</li> <li>Metrics Explorer - Analyze cardinality, labels, and raw series data</li> <li>Service catalog - RED metrics (Rate, Errors, Duration) for all services</li> <li>Interactive service map - Visualize dependencies and call graphs</li> <li>OpenTelemetry Collector management - Remote configuration management via OpAMP protocol</li> <li>REST API - Programmatic access with OpenAPI documentation</li> <li>Zero vendor lock-in - Works with any OTel Collector distribution</li> </ul> <p>Local Development Only</p> <p>TinyOlly is not designed to compete with production observability platforms! It's for local development only and is not focused on infrastructure monitoring at this time.</p>"},{"location":"#platform-support","title":"Platform Support","text":"<p>Tested on:</p> <ul> <li>Docker Desktop (macOS Apple Silicon)</li> <li>Minikube Kubernetes (macOS Apple Silicon)</li> <li>May work on other platforms</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Ready to try TinyOlly? Check out the Quick Start Guide to get running in under 5 minutes!</p>"},{"location":"#screenshots","title":"Screenshots","text":"Trace Waterfall with Correlated Logs Real-time Logs with Filtering Metrics with Chart Visualization Service Catalog with RED Metrics Interactive Service Dependency Map OTel Collector Configuration (OpAMP) <p>Built for the OpenTelemetry community</p> <p> GitHub \u2022     Issues </p>"},{"location":"CARDINALITY-PROTECTION/","title":"Cardinality Protection","text":"<p>Span waterfall showing distributed trace complexity</p> <p>TinyOlly includes built-in protection against metric cardinality explosion with a configurable limit on unique metric names.</p>"},{"location":"CARDINALITY-PROTECTION/#configuration","title":"Configuration","text":""},{"location":"CARDINALITY-PROTECTION/#environment-variables","title":"Environment Variables","text":"Variable Default Description <code>MAX_METRIC_CARDINALITY</code> 1000 Maximum unique metric names <code>REDIS_TTL</code> 1800 Metric retention (seconds)"},{"location":"CARDINALITY-PROTECTION/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>Update <code>k8s/tinyolly-otlp-receiver.yaml</code>:</p> <pre><code>env:\n  - name: MAX_METRIC_CARDINALITY\n    value: \"2000\"  # Increase limit\n  - name: REDIS_TTL\n    value: \"3600\"  # 1 hour retention\n</code></pre>"},{"location":"CARDINALITY-PROTECTION/#docker-deployment","title":"Docker Deployment","text":"<p>Update <code>docker-compose-tinyolly-core.yml</code> in the <code>docker/</code> directory:</p> <pre><code>environment:\n  MAX_METRIC_CARDINALITY: 2000\n  REDIS_TTL: 3600\n</code></pre>"},{"location":"CARDINALITY-PROTECTION/#monitoring","title":"Monitoring","text":"<p>The UI displays cardinality warnings when approaching the limit: - Yellow Warning: 70-90% of limit reached - Red Alert: 90%+ of limit reached</p> <p>Check current cardinality via the API:</p> <pre><code>curl http://localhost:5005/api/stats\n</code></pre> <p>Response: <pre><code>{\n  \"traces\": 145,\n  \"logs\": 892,\n  \"metrics\": 850,\n  \"metrics_max\": 1000,\n  \"metrics_dropped\": 23\n}\n</code></pre></p>"},{"location":"api/","title":"REST API &amp; OpenAPI","text":"<p>OpenAPI documentation with interactive Swagger UI</p> <p>TinyOlly provides a comprehensive REST API for programmatic access to all telemetry data in OpenTelemetry-native format.</p>"},{"location":"api/#interactive-api-documentation","title":"Interactive API Documentation","text":"<p>Access the auto-generated OpenAPI documentation: - Swagger UI: <code>http://localhost:5005/docs</code> - Interactive API explorer - ReDoc: <code>http://localhost:5005/redoc</code> - Alternative documentation - OpenAPI Spec: <code>http://localhost:5005/openapi.json</code> - Machine-readable schema</p> <p>All APIs return OpenTelemetry-native JSON with: - Resources: <code>service.name</code>, <code>host.name</code>, etc. - Attributes: Metric labels and span attributes - Full Context: Trace/span IDs, timestamps, status codes</p>"},{"location":"api/#api-endpoints-overview","title":"API Endpoints Overview","text":"<p>The REST API provides endpoints for:</p> Endpoint Method Description <code>/api/traces</code> GET List recent traces with filtering <code>/api/traces/{trace_id}</code> GET Get detailed trace with all spans <code>/api/spans</code> GET List recent spans with filtering <code>/api/logs</code> GET Retrieve logs with trace correlation <code>/api/metrics</code> GET Query time-series metrics <code>/api/service-map</code> GET Get service dependency graph <code>/api/service-catalog</code> GET List services with RED metrics <code>/api/stats</code> GET System stats and cardinality info <code>/admin/stats</code> GET Detailed admin statistics <code>/health</code> GET Health check endpoint <p>All endpoints return data in standard OpenTelemetry format, ensuring compatibility with OpenTelemetry tooling and standards.</p>"},{"location":"api/#common-api-workflows","title":"Common API Workflows","text":""},{"location":"api/#1-get-all-recent-traces","title":"1. Get All Recent Traces","text":"<p>Retrieve the last 50 traces:</p> cURLPythonJavaScript <pre><code>curl http://localhost:5005/api/traces?limit=50\n</code></pre> <pre><code>import requests\n\nresponse = requests.get('http://localhost:5005/api/traces', params={'limit': 50})\ntraces = response.json()\n\nfor trace in traces:\n    print(f\"Trace {trace['trace_id']}: {trace['service_name']} - {trace['name']}\")\n</code></pre> <pre><code>fetch('http://localhost:5005/api/traces?limit=50')\n  .then(response =&gt; response.json())\n  .then(traces =&gt; {\n    traces.forEach(trace =&gt; {\n      console.log(`Trace ${trace.trace_id}: ${trace.service_name} - ${trace.name}`);\n    });\n  });\n</code></pre> <p>Response Format: <pre><code>[\n  {\n    \"trace_id\": \"a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\",\n    \"service_name\": \"demo-frontend\",\n    \"name\": \"GET /products\",\n    \"start_time\": 1701234567890000000,\n    \"duration_ms\": 125.4,\n    \"status_code\": 200,\n    \"method\": \"GET\",\n    \"route\": \"/products\",\n    \"span_count\": 5\n  }\n]\n</code></pre></p>"},{"location":"api/#2-get-detailed-trace-with-waterfall","title":"2. Get Detailed Trace with Waterfall","text":"<p>Retrieve a complete trace with all spans for waterfall visualization:</p> cURLPython <pre><code>curl http://localhost:5005/api/traces/a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\n</code></pre> <pre><code>import requests\n\ntrace_id = \"a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\"\nresponse = requests.get(f'http://localhost:5005/api/traces/{trace_id}')\ntrace = response.json()\n\nprint(f\"Trace: {trace['name']}\")\nprint(f\"Total spans: {len(trace['spans'])}\")\nprint(f\"Duration: {trace['duration_ms']}ms\")\n\nfor span in trace['spans']:\n    indent = \"  \" * span.get('level', 0)\n    print(f\"{indent}{span['name']} ({span['duration_ms']}ms)\")\n</code></pre> <p>Response Format: <pre><code>{\n  \"trace_id\": \"a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\",\n  \"name\": \"GET /products\",\n  \"service_name\": \"demo-frontend\",\n  \"start_time\": 1701234567890000000,\n  \"duration_ms\": 125.4,\n  \"span_count\": 5,\n  \"spans\": [\n    {\n      \"span_id\": \"1234567890abcdef\",\n      \"parent_span_id\": null,\n      \"name\": \"GET /products\",\n      \"service_name\": \"demo-frontend\",\n      \"start_time\": 1701234567890000000,\n      \"duration_ms\": 125.4,\n      \"status\": {\"code\": 1},\n      \"attributes\": {\n        \"http.method\": \"GET\",\n        \"http.route\": \"/products\",\n        \"http.status_code\": 200\n      }\n    }\n  ]\n}\n</code></pre></p>"},{"location":"api/#3-find-logs-for-a-specific-trace","title":"3. Find Logs for a Specific Trace","text":"<p>Correlate logs with a trace using trace_id:</p> cURLPython <pre><code>curl \"http://localhost:5005/api/logs?trace_id=a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\"\n</code></pre> <pre><code>import requests\n\ntrace_id = \"a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\"\nresponse = requests.get('http://localhost:5005/api/logs',\n                       params={'trace_id': trace_id})\nlogs = response.json()\n\nfor log in logs:\n    print(f\"[{log['severity']}] {log['body']}\")\n</code></pre> <p>Response Format: <pre><code>[\n  {\n    \"timestamp\": 1701234567890000000,\n    \"trace_id\": \"a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6\",\n    \"span_id\": \"1234567890abcdef\",\n    \"severity\": \"INFO\",\n    \"body\": \"Processing product request\",\n    \"service_name\": \"demo-frontend\",\n    \"attributes\": {\n      \"user_id\": \"12345\"\n    }\n  }\n]\n</code></pre></p>"},{"location":"api/#4-query-metrics","title":"4. Query Metrics","text":"<p>Retrieve metrics data:</p> cURLPython <pre><code>curl http://localhost:5005/api/metrics\n</code></pre> <pre><code>import requests\n\nresponse = requests.get('http://localhost:5005/api/metrics')\nmetrics = response.json()\n\nfor metric in metrics:\n    print(f\"{metric['name']} ({metric['type']})\")\n    for series in metric.get('series', []):\n        labels = ', '.join(f\"{k}={v}\" for k, v in series.get('attributes', {}).items())\n        print(f\"  [{labels}] = {series.get('value', 'N/A')}\")\n</code></pre> <p>Response Format: <pre><code>[\n  {\n    \"name\": \"http.server.duration\",\n    \"type\": \"histogram\",\n    \"description\": \"HTTP request duration\",\n    \"unit\": \"ms\",\n    \"series\": [\n      {\n        \"attributes\": {\n          \"http.method\": \"GET\",\n          \"http.route\": \"/products\",\n          \"service.name\": \"demo-frontend\"\n        },\n        \"data_points\": [\n          {\n            \"timestamp\": 1701234567890000000,\n            \"count\": 42,\n            \"sum\": 5250.5,\n            \"bucket_counts\": [10, 20, 10, 2]\n          }\n        ]\n      }\n    ]\n  }\n]\n</code></pre></p>"},{"location":"api/#5-get-service-catalog-with-red-metrics","title":"5. Get Service Catalog with RED Metrics","text":"<p>List all services with Rate, Errors, and Duration metrics:</p> cURLPython <pre><code>curl http://localhost:5005/api/service-catalog\n</code></pre> <pre><code>import requests\n\nresponse = requests.get('http://localhost:5005/api/service-catalog')\nservices = response.json()\n\nfor service in services:\n    print(f\"\\n{service['service_name']}\")\n    print(f\"  Request Rate: {service.get('request_rate', 0):.2f} req/s\")\n    print(f\"  Error Rate: {service.get('error_rate', 0):.2f}%\")\n    print(f\"  P50 Latency: {service.get('p50_latency', 0):.2f}ms\")\n    print(f\"  P95 Latency: {service.get('p95_latency', 0):.2f}ms\")\n</code></pre> <p>Response Format: <pre><code>[\n  {\n    \"service_name\": \"demo-frontend\",\n    \"span_count\": 1523,\n    \"request_rate\": 12.5,\n    \"error_rate\": 2.3,\n    \"p50_latency\": 45.2,\n    \"p95_latency\": 125.7,\n    \"p99_latency\": 250.3,\n    \"first_seen\": 1701234567890000000,\n    \"last_seen\": 1701238167890000000\n  }\n]\n</code></pre></p>"},{"location":"api/#6-get-service-dependency-map","title":"6. Get Service Dependency Map","text":"<p>Retrieve the service dependency graph:</p> cURLPython <pre><code>curl http://localhost:5005/api/service-map\n</code></pre> <pre><code>import requests\n\nresponse = requests.get('http://localhost:5005/api/service-map')\ngraph = response.json()\n\nprint(\"Services:\", len(graph['nodes']))\nfor node in graph['nodes']:\n    print(f\"  - {node['service_name']} ({node['type']})\")\n\nprint(\"\\nConnections:\", len(graph['edges']))\nfor edge in graph['edges']:\n    print(f\"  {edge['source']} \u2192 {edge['target']} ({edge['call_count']} calls)\")\n</code></pre> <p>Response Format: <pre><code>{\n  \"nodes\": [\n    {\n      \"service_name\": \"demo-frontend\",\n      \"type\": \"server\",\n      \"span_count\": 1523\n    },\n    {\n      \"service_name\": \"demo-backend\",\n      \"type\": \"server\",\n      \"span_count\": 3046\n    }\n  ],\n  \"edges\": [\n    {\n      \"source\": \"demo-frontend\",\n      \"target\": \"demo-backend\",\n      \"call_count\": 1523\n    }\n  ]\n}\n</code></pre></p>"},{"location":"api/#7-check-system-statistics","title":"7. Check System Statistics","text":"<p>Get Redis memory usage and cardinality metrics:</p> cURLPython <pre><code>curl http://localhost:5005/api/stats\n</code></pre> <pre><code>import requests\n\nresponse = requests.get('http://localhost:5005/api/stats')\nstats = response.json()\n\nprint(f\"Total Traces: {stats.get('total_traces', 0)}\")\nprint(f\"Total Spans: {stats.get('total_spans', 0)}\")\nprint(f\"Total Logs: {stats.get('total_logs', 0)}\")\nprint(f\"Total Metrics: {stats.get('total_metrics', 0)}\")\nprint(f\"Unique Metric Names: {stats.get('unique_metric_names', 0)}\")\nprint(f\"Redis Memory: {stats.get('redis_memory_mb', 0):.2f} MB\")\n</code></pre> <p>Response Format: <pre><code>{\n  \"total_traces\": 1523,\n  \"total_spans\": 7615,\n  \"total_logs\": 15230,\n  \"total_metrics\": 45,\n  \"unique_metric_names\": 12,\n  \"redis_memory_mb\": 45.7,\n  \"cardinality_limit\": 1000,\n  \"cardinality_usage_pct\": 1.2,\n  \"uptime_seconds\": 3600\n}\n</code></pre></p>"},{"location":"api/#advanced-filtering","title":"Advanced Filtering","text":""},{"location":"api/#filter-spans-by-service","title":"Filter Spans by Service","text":"<pre><code>curl \"http://localhost:5005/api/spans?service=demo-frontend&amp;limit=100\"\n</code></pre>"},{"location":"api/#filter-logs-by-severity","title":"Filter Logs by Severity","text":"<pre><code>curl \"http://localhost:5005/api/logs?severity=ERROR&amp;limit=50\"\n</code></pre>"},{"location":"api/#time-based-queries","title":"Time-based Queries","text":"<p>All endpoints support <code>start_time</code> and <code>end_time</code> parameters (Unix nanoseconds):</p> <pre><code># Get traces from the last hour\nSTART=$(date -u -d '1 hour ago' +%s)000000000\nEND=$(date -u +%s)000000000\ncurl \"http://localhost:5005/api/traces?start_time=$START&amp;end_time=$END\"\n</code></pre>"},{"location":"api/#client-generation","title":"Client Generation","text":"<p>Generate API clients in any language using the OpenAPI spec:</p> <pre><code># Download OpenAPI spec\ncurl http://localhost:5005/openapi.json &gt; tinyolly-openapi.json\n\n# Generate Python client\nopenapi-generator-cli generate \\\n  -i tinyolly-openapi.json \\\n  -g python \\\n  -o ./tinyolly-python-client\n\n# Generate Go client\nopenapi-generator-cli generate \\\n  -i tinyolly-openapi.json \\\n  -g go \\\n  -o ./tinyolly-go-client\n\n# Generate TypeScript client\nopenapi-generator-cli generate \\\n  -i tinyolly-openapi.json \\\n  -g typescript-fetch \\\n  -o ./tinyolly-ts-client\n</code></pre>"},{"location":"api/#rate-limits","title":"Rate Limits","text":"<p>TinyOlly is designed for local development and has no rate limits. However:</p> <ul> <li>Memory limits apply based on Redis configuration (default: 256MB)</li> <li>Cardinality protection limits unique metric names to 1000 (configurable)</li> <li>TTL: All data expires after 30 minutes</li> </ul>"},{"location":"api/#authentication","title":"Authentication","text":"<p>TinyOlly is designed for local development and does not include authentication. Do not expose TinyOlly to the internet without adding authentication via a reverse proxy.</p>"},{"location":"api/#need-help","title":"Need Help?","text":"<ul> <li>View interactive examples in Swagger UI</li> <li>Open an issue on GitHub</li> <li>Read the technical architecture</li> </ul>"},{"location":"docker/","title":"Docker Deployment","text":"<p>Get TinyOlly running on Docker in minutes!</p> <p>TinyOlly UI showing distributed traces</p> <p>All examples are launched from the repo - clone it first or download the current GitHub release archive: <pre><code>git clone https://github.com/tinyolly/tinyolly\n</code></pre></p>"},{"location":"docker/#1-deploy-tinyolly-core-required","title":"1. Deploy TinyOlly Core (Required)","text":"<p>Start the observability backend (OTel Collector, TinyOlly Receiver, Redis, UI):</p> <pre><code>cd docker\n./01-start-core.sh\n</code></pre> <p>This starts: - OTel Collector: Listening on <code>localhost:4317</code> (gRPC) and <code>localhost:4318</code> (HTTP) - OpAMP Server: <code>ws://localhost:4320/v1/opamp</code> (WebSocket), <code>localhost:4321</code> (HTTP REST API) - TinyOlly UI: <code>http://localhost:5005</code> - TinyOlly OTLP Receiver and its Redis storage: OTLP observability back end and storage - Rebuilds images if code changes are detected  </p> <p>Open the UI: <code>http://localhost:5005</code> (empty until you send data)</p> <p>OpenTelemetry Collector + OpAMP Config Page: Navigate to the \"OpenTelemetry Collector + OpAMP Config\" tab in the UI to view and manage collector configurations remotely. See the OpAMP Configuration section below for setup instructions.</p> <p>Stop core services: <pre><code>./02-stop-core.sh\n</code></pre></p>"},{"location":"docker/#2-deploy-demo-apps-optional","title":"2. Deploy Demo Apps (Optional)","text":"<p>Deploy two Flask microservices with automatic traffic generation:</p> <pre><code>cd docker-demo\n./01-deploy-demo.sh\n</code></pre> <p>Wait 30 seconds. The demo apps automatically generate traffic - traces, logs, and metrics will appear in the UI!</p> <p>Stop demo apps: <pre><code>./02-cleanup-demo.sh\n</code></pre></p> <p>This leaves TinyOlly core running. To stop everything: <pre><code>cd docker\n./02-stop-core.sh\n</code></pre></p>"},{"location":"docker/#3-opentelemetry-demo-20-services-optional","title":"3. OpenTelemetry Demo (~20 Services - Optional)","text":"<p>Prerequisites: Clone the OpenTelemetry Demo first: <pre><code>git clone https://github.com/open-telemetry/opentelemetry-demo\ncd opentelemetry-demo\n</code></pre></p> <p>Configure: Edit <code>src/otel-collector/otelcol-config-extras.yml</code>: <pre><code>exporters:\n  otlphttp/tinyolly:\n    endpoint: http://otel-collector:4318\n\nservice:\n  pipelines:\n    traces:\n      exporters: [spanmetrics, otlphttp/tinyolly]\n</code></pre></p> <p>Deploy: <pre><code>export OTEL_COLLECTOR_HOST=host.docker.internal\ndocker compose up \\\n  --scale otel-collector=0 \\\n  --scale prometheus=0 \\\n  --scale grafana=0 \\\n  --scale jaeger=0 \\\n  --scale opensearch=0 \\\n  --force-recreate \\\n  --remove-orphans \\\n  --detach\n</code></pre></p> <p>Stop: <pre><code>docker compose down\n</code></pre></p> <p>Note</p> <p>This disables the demo's built-in collector, Jaeger, OpenSearch, Grafana, and Prometheus. All telemetry routes to Otel Collector -&gt; TinyOlly.</p>"},{"location":"docker/#4-use-tinyolly-with-your-own-apps","title":"4. Use TinyOlly with Your Own Apps","text":"<p>After deploying TinyOlly core (step 1 above), instrument your application to send telemetry:</p> <p>For apps running in Docker containers: Point your OpenTelemetry exporter to: - gRPC: <code>http://otel-collector:4317</code> - HTTP: <code>http://otel-collector:4318</code> </p> <p>For apps running on your host machine (outside Docker): Docker Desktop automatically exposes container ports to <code>localhost</code>. Point your OpenTelemetry exporter to: - gRPC: <code>http://localhost:4317</code> - HTTP: <code>http://localhost:4318</code> </p> <p>Example environment variables: <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\n</code></pre></p> <p>The Otel Collector will forward everything to TinyOlly's OTLP receiver, which process telemetry and stores it in Redis in OTEL format for the backend and UI to access.</p>"},{"location":"docker/#5-tinyolly-core-only-deployment-use-your-own-docker-opentelemetry-collector","title":"5. TinyOlly Core-Only Deployment: Use Your Own Docker OpenTelemetry Collector","text":"<p>If you already have an OpenTelemetry Collector or want to send telemetry directly to the TinyOlly Receiver, you can deploy the core components without the bundled OTel Collector.</p> <pre><code>cd docker-core-only\n./01-start-core.sh\n</code></pre> <p>This starts: - TinyOlly OTLP Receiver: Listening on <code>localhost:4343</code> (gRPC only) - OpAMP Server: <code>ws://localhost:4320/v1/opamp</code> (WebSocket), <code>localhost:4321</code> (HTTP REST API) - TinyOlly UI: <code>http://localhost:5005</code> - TinyOlly Redis: <code>localhost:6579</code></p> <p>Swap out the included Otel Collector for any distro of Otel Collector.</p> <p>Point your OpenTelemetry exporters to tinyolly-otlp-receiver:4343: i.e. <pre><code>exporters:\n  debug:\n    verbosity: detailed\n\n  otlp:\n    endpoint: \"tinyolly-otlp-receiver:4343\"\n    tls:\n      insecure: true\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, otlp, spanmetrics]\n\n    metrics:\n      receivers: [otlp,spanmetrics]\n      processors: [batch]\n      exporters: [debug, otlp]\n\n    logs:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, otlp]\n</code></pre></p> <p>The Otel Collector will forward everything to TinyOlly's OTLP receiver, which process telemetry and stores it in Redis in OTEL format for the backend and UI to access.</p>"},{"location":"docker/#opamp-configuration-optional","title":"OpAMP Configuration (Optional)","text":"<p>The OpenTelemetry Collector + OpAMP Config page in the TinyOlly UI allows you to view and manage collector configurations remotely. To enable this feature, add the OpAMP extension to your collector config:</p> <pre><code>extensions:\n  opamp:\n    server:\n      ws:\n        endpoint: ws://localhost:4320/v1/opamp\n\nservice:\n  extensions: [opamp]\n</code></pre> <p>The default configuration template (located at <code>docker/otelcol-configs/config.yaml</code>) shows a complete example with OTLP receivers, OpAMP extension, batch processing, and spanmetrics connector. Your collector will connect to the OpAMP server and receive configuration updates through the TinyOlly UI.</p> <p>Stop core-only services: <pre><code>./02-stop-core.sh\n</code></pre></p>"},{"location":"kubernetes/","title":"Kubernetes Deployment","text":"<p>Deploy TinyOlly on Kubernetes (Minikube) for local development!</p> <p>Service map showing microservices running on Kubernetes</p> <p>All examples are launched from the repo - clone it first or download the current GitHub release archive: <pre><code>git clone https://github.com/tinyolly/tinyolly\n</code></pre></p>"},{"location":"kubernetes/#prerequisites","title":"Prerequisites","text":"<ul> <li>Minikube</li> <li>kubectl</li> </ul>"},{"location":"kubernetes/#1-deploy-tinyolly-core","title":"1. Deploy TinyOlly Core","text":"<ol> <li> <p>Start Minikube:</p> <pre><code>minikube start\n</code></pre> </li> <li> <p>Build Images:</p> <p>Run the build script to build the Docker images inside Minikube's Docker daemon:</p> <pre><code>./k8s/01-build-images.sh\n</code></pre> </li> <li> <p>Apply Manifests:</p> <p>Apply the Kubernetes manifests to deploy the services:</p> <pre><code>./k8s/02-deploy-tinyolly.sh\n</code></pre> <p>Or manually apply all manifests:</p> <pre><code>kubectl apply -f k8s/\n</code></pre> </li> <li> <p>Access the UI:</p> <p>To access the TinyOlly UI (Service Type: LoadBalancer) on macOS with Minikube, you need to use <code>minikube tunnel</code>.</p> <p>Open a new terminal window and run:</p> <pre><code>minikube tunnel\n</code></pre> <p>You may be asked for your password. Keep this terminal open.</p> <p>Now you can access the TinyOlly UI at: http://localhost:5002</p> <p>OpenTelemetry Collector + OpAMP Config Page: Navigate to the \"OpenTelemetry Collector + OpAMP Config\" tab in the UI to view and manage collector configurations remotely. See the OpAMP Configuration section below for setup instructions.</p> </li> <li> <p>Send Telemetry from Host Apps:</p> <p>To send telemetry from applications running on your host machine (outside Kubernetes), use <code>kubectl port-forward</code> to expose the OTel Collector ports:</p> <p>Open a new terminal window and run:</p> <pre><code>kubectl port-forward service/otel-collector 4317:4317 4318:4318\n</code></pre> <p>Keep this terminal open. Now point your application's OpenTelemetry exporter to: - gRPC: <code>http://localhost:4317</code> - HTTP: <code>http://localhost:4318</code> </p> <p>Example environment variables: <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\n</code></pre></p> <p>For apps running inside the Kubernetes cluster: Use the Kubernetes service name: - gRPC: <code>http://otel-collector:4317</code> - HTTP: <code>http://otel-collector:4318</code> </p> </li> <li> <p>Clean Up:</p> <p>Use the cleanup script to remove all TinyOlly resources:</p> <pre><code>./k8s/03-cleanup.sh\n</code></pre> <p>Shut down Minikube: <pre><code>minikube stop\n</code></pre></p> <p>Minikube may be more stable if you delete it: <pre><code>minikube delete\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/#2-demo-applications-optional","title":"2. Demo Applications (Optional)","text":"<p>To see TinyOlly in action with instrumented microservices:</p> <pre><code>cd k8s-demo\n./02-deploy.sh\n</code></pre> <p>The deploy script automatically builds the demo images if needed. To manually rebuild images: <pre><code>./01-build-images.sh\n</code></pre></p> <p>To clean up the demo: <pre><code>./03-cleanup.sh\n</code></pre></p> <p>The demo includes two microservices that automatically generate traffic, showcasing distributed tracing across service boundaries.</p>"},{"location":"kubernetes/#3-opentelemetry-demo-20-services-optional","title":"3. OpenTelemetry Demo (~20 Services - Optional)","text":"<p>To deploy the full OpenTelemetry Demo with ~20 microservices:</p> <p>Prerequisites: - TinyOlly must be deployed first (see Setup above) - Helm installed - Sufficient cluster resources (demo is resource-intensive)  </p> <p>Deploy: <pre><code>cd k8s-otel-demo\n./01-deploy-otel-demo-helm.sh\n</code></pre></p> <p>This deploys all OpenTelemetry Demo services configured to send telemetry to TinyOlly's collector via HTTP on port 4318. Built-in observability tools (Jaeger, Grafana, Prometheus) are disabled.</p> <p>Cleanup: <pre><code>cd k8s-otel-demo\n./02-cleanup-otel-demo-helm.sh\n</code></pre></p> <p>This removes the OpenTelemetry Demo but leaves TinyOlly running.</p>"},{"location":"kubernetes/#4-tinyolly-core-only-deployment-use-your-own-kubernetes-opentelemetry-collector","title":"4. TinyOlly Core-Only Deployment: Use Your Own Kubernetes OpenTelemetry Collector","text":"<p>To deploy TinyOlly without the bundled OTel Collector (e.g., if you have an existing collector daemonset). Includes OpAMP server for optional remote collector configuration management:</p> <ol> <li> <p>Build Images: <pre><code>./k8s/01-build-images.sh\n</code></pre></p> </li> <li> <p>Deploy Core: <pre><code>cd k8s-core-only\n./01-deploy.sh\n</code></pre></p> </li> <li> <p>Access UI:     Run <code>minikube tunnel</code> and access <code>http://localhost:5002</code>.</p> </li> <li> <p>Cleanup: <pre><code>./02-cleanup.sh\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/#use-tinyolly-with-any-opentelemetry-collector","title":"Use TinyOlly with Any OpenTelemetry Collector","text":"<p>Swap out the included Otel Collector for any distro of Otel Collector.</p> <p>Point your OpenTelemetry exporters to tinyolly-otlp-receiver:4343: i.e. <pre><code>exporters:\n  debug:\n    verbosity: detailed\n\n  otlp:\n    endpoint: \"tinyolly-otlp-receiver:4343\"\n    tls:\n      insecure: true\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, otlp, spanmetrics]\n\n    metrics:\n      receivers: [otlp,spanmetrics]\n      processors: [batch]\n      exporters: [debug, otlp]\n\n    logs:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, otlp]\n</code></pre></p> <p>The Otel Collector will forward everything to TinyOlly's OTLP receiver, which process telemetry and stores it in Redis in OTEL format for the backend and UI to access.</p>"},{"location":"kubernetes/#opamp-configuration-optional","title":"OpAMP Configuration (Optional)","text":"<p>The OpenTelemetry Collector + OpAMP Config page in the TinyOlly UI allows you to view and manage collector configurations remotely. To enable this feature, add the OpAMP extension to your collector config:</p> <pre><code>extensions:\n  opamp:\n    server:\n      ws:\n        endpoint: ws://tinyolly-opamp-server:4320/v1/opamp\n\nservice:\n  extensions: [opamp]\n</code></pre> <p>The default configuration template (included as a ConfigMap in <code>k8s-core-only/tinyolly-opamp-server.yaml</code>) shows a complete example with OTLP receivers, OpAMP extension, batch processing, and spanmetrics connector. Your collector will connect to the OpAMP server and receive configuration updates through the TinyOlly UI.</p>"},{"location":"licensing/","title":"Licensing","text":"<p>TinyOlly is released under the BSD 3-Clause License. The full license text is available in the LICENSE file. This license permits free use, modification, and redistribution for individuals, researchers, and small organizations.</p>"},{"location":"licensing/#community-and-small-scale-use","title":"Community and Small-Scale Use","text":"<p>TinyOlly may be used freely under the BSD license for:</p> <ul> <li>Individual developers and hobby projects  </li> <li>Academic and research use  </li> <li>Startups or small organizations  </li> <li>Limited internal development, tooling, experimentation, or evaluation  </li> </ul> <p>No additional agreements are required for these scenarios.</p>"},{"location":"licensing/#commercial-and-large-scale-use","title":"Commercial and Large-Scale Use","text":"<p>Organizations deploying TinyOlly in a broader or more intensive capacity are required to obtain a commercial license. This includes use cases such as:</p> <ul> <li>Organizations with approximately 50 or more employees  </li> <li>Deployments across multiple engineering teams  </li> <li>Production or mission-critical observability workflows  </li> <li>Integration into commercial software, platforms, or SaaS products  </li> <li>High-volume or distributed environments</li> </ul> <p>For commercial licensing inquiries, contact:  </p>"},{"location":"licensing/#rationale","title":"Rationale","text":"<p>This model ensures that TinyOlly remains fully open source and accessible to the community while providing a sustainable path for supporting organizations that rely on it at scale.</p>"},{"location":"metrics/","title":"Metrics &amp; Cardinality explorer","text":"<p>TinyOlly provides a powerful interface for analyzing OpenTelemetry metrics, with specific tools designed to help you understand the shape and cardinality of your telemetry data.</p>"},{"location":"metrics/#metrics-table","title":"Metrics Table","text":"<p>The metrics table offers a dense, high-information view of all ingested metrics.</p> <p></p> <p>Click the Chart button to visualize metric data over time:</p> <p></p>"},{"location":"metrics/#key-columns","title":"Key Columns","text":"<ul> <li>Name: The full OTel metric name (e.g., <code>http.server.response.size</code>).</li> <li>Unit: The unit of measurement (e.g., <code>By</code>, <code>ms</code>).</li> <li>Type: The metric type (Histogram, Sum, Gauge, etc.).</li> <li>Resources: Click to view the unique resource combinations associated with this metric.</li> <li>Cardinality: Shows the number of label dimensions vs the total number of unique time series (e.g., <code>8 labels / 185 series</code>).</li> </ul>"},{"location":"metrics/#cardinality-explorer","title":"Cardinality Explorer","text":"<p>Clicking on the blue Cardinality link for any metric opens the Cardinality Explorer. This tool is essential for understanding \"high cardinality\" issues and exploring your data's dimensions.</p>"},{"location":"metrics/#1-header-stats","title":"1. Header Stats","text":"<ul> <li>Total Series (Historic): The total number of unique time series seen for this metric since startup (persisted in Redis).</li> <li>Active Series (1h): The count of series seen in the last hour.</li> <li>Label Dimensions: The number of unique label keys (e.g., <code>http.method</code>, <code>http.status_code</code>).</li> </ul>"},{"location":"metrics/#2-label-analysis-table","title":"2. Label Analysis Table","text":"<p>This table helps you identify which labels are contributing most to your cardinality.</p> <ul> <li>Label Name: The key of the label.</li> <li>Cardinality: The number of unique values for this label.</li> <li>Values (Top 5): A preview of the most common values.<ul> <li>If there are more than 5 values, a clickable <code>...</code> link expands the list to show all values inline.</li> </ul> </li> </ul>"},{"location":"metrics/#3-raw-active-series","title":"3. Raw Active Series","text":"<p>A scrollable view of all active series in a PromQL-like syntax:</p> <pre><code>{container.id=\"...\", http.method=\"GET\", http.route=\"/api/traces\", http.status_code=\"200\", service.name=\"tinyolly-ui\"}\n{container.id=\"...\", http.method=\"GET\", http.route=\"/health\", http.status_code=\"200\", service.name=\"tinyolly-ui\"}\n</code></pre>"},{"location":"metrics/#export-actions","title":"Export Actions","text":"<p>Use the buttons in the \"Raw Active Series\" section to export data for offline analysis:</p> <ul> <li>Copy PromQL: Copies the visible series list to your clipboard.</li> <li>Download JSON: Downloads the full series object as a JSON file.</li> </ul>"},{"location":"metrics/#cardinality-protection","title":"Cardinality Protection","text":"<p>TinyOlly includes built-in protection against cardinality explosions to prevent memory exhaustion during local development.</p> <ul> <li>Hard Limit: 1000 unique metric names (configurable).</li> <li>Visual Warnings: <ul> <li>\u26a0\ufe0f Yellow: &gt; 70% capacity</li> <li>\ud83d\udd34 Red: &gt; 90% capacity</li> </ul> </li> <li>Behavior: Metrics exceeding the limit are dropped, and a system alert is triggered.</li> </ul> <p>See Cardinality Protection for more details.</p>"},{"location":"otel-collector/","title":"OpenTelemetry Collector","text":"<p>OpenTelemetry Collector configuration management via OpAMP</p> <p>TinyOlly uses the OpenTelemetry Collector as the telemetry ingestion and shipping layer. The collector receives telemetry from your applications and forwards it to TinyOlly's OTLP receiver.</p>"},{"location":"otel-collector/#opentelemetry-collector-opamp-config-page","title":"OpenTelemetry Collector + OpAMP Config Page","text":"<p>TinyOlly includes a web interface for managing OpenTelemetry Collector configurations via the OpAMP (Open Agent Management Protocol). Access this page through the \"OpenTelemetry Collector + OpAMP Config\" tab in the TinyOlly UI.</p> <p>Features: - View current configuration from connected collectors - Apply configuration changes with real-time validation - Browse configuration templates for common use cases - Monitor OpAMP server status and connected agents - Preview configuration diffs before applying</p> <p>Requirements: - Your collector must be configured with the OpAMP extension (see OpAMP Configuration below) - Collector must be connected to the OpAMP server</p>"},{"location":"otel-collector/#configuration","title":"Configuration","text":"<p>TinyOlly includes a sample collector configuration that you can customize for your needs. The configuration files are located at:</p> <ul> <li>Docker: <code>docker/otelcol-configs/config.yaml</code></li> <li>Kubernetes: <code>k8s/otel-collector-config.yaml</code></li> </ul>"},{"location":"otel-collector/#default-configuration","title":"Default Configuration","text":"<p>The default configuration includes:</p> <ul> <li>OTLP Receivers: Accepts telemetry on ports 4317 (gRPC) and 4318 (HTTP)</li> <li>OpAMP Extension: Enables remote configuration management via TinyOlly UI</li> <li>Span Metrics Connector: Automatically generates RED metrics from traces</li> <li>Batch Processor: Batches telemetry for efficient processing</li> <li>OTLP Exporter: Forwards all telemetry to TinyOlly's OTLP receiver</li> </ul>"},{"location":"otel-collector/#customization-examples","title":"Customization Examples","text":"<p>You can extend the collector configuration to add additional capabilities. The collector uses the <code>otel/opentelemetry-collector-contrib</code> image which includes:</p> <ul> <li>Receivers: OTLP, Prometheus, Jaeger, Zipkin, and many more</li> <li>Processors: Batch, Memory Limiter, Resource Detection, Tail Sampling, Filtering</li> <li>Connectors: Span Metrics, Service Graph</li> <li>Exporters: OTLP, Prometheus, Logging, and many more</li> </ul> <p>For a complete list of available components, see the OpenTelemetry Collector Contrib documentation.</p>"},{"location":"otel-collector/#applying-changes","title":"Applying Changes","text":""},{"location":"otel-collector/#docker","title":"Docker","text":"<p>After modifying <code>docker/otelcol-configs/config.yaml</code> rebuild/restart using: <pre><code>cd docker\n./01-start-core.sh\n</code></pre></p>"},{"location":"otel-collector/#kubernetes","title":"Kubernetes","text":"<p>After modifying <code>k8s/otel-collector-config.yaml</code>: rebuild/restart using: <pre><code>kubectl apply -f k8s/otel-collector-config.yaml\nkubectl rollout restart deployment/otel-collector\n</code></pre></p>"},{"location":"otel-collector/#using-your-own-collector","title":"Using Your Own Collector","text":"<p>You can use your own OpenTelemetry Collector instance instead of the one bundled with TinyOlly. This is useful if you have an existing collector setup or want to test specific collector configurations.</p> <p>To do this, deploy the Core-Only version of TinyOlly (see Docker Deployment or Kubernetes Deployment).</p> <p>Then, configure your collector's OTLP exporter to send data to the TinyOlly Receiver:</p> <ul> <li>Endpoint: <code>tinyolly-otlp-receiver:4343</code> (or <code>localhost:4343</code> from host)</li> <li>Protocol: gRPC</li> <li>TLS: Insecure (or configured as needed)</li> </ul> <p>Example Exporter Configuration: <pre><code>exporters:\n  otlp:\n    endpoint: \"tinyolly-otlp-receiver:4343\"\n    tls:\n      insecure: true\n</code></pre></p>"},{"location":"otel-collector/#opamp-configuration-optional","title":"OpAMP Configuration (Optional)","text":"<p>The OpenTelemetry Collector + OpAMP Config page in the TinyOlly UI allows you to view and manage collector configurations remotely. To enable this feature, add the OpAMP extension to your collector config:</p> <pre><code>extensions:\n  opamp:\n    server:\n      ws:\n        endpoint: ws://localhost:4320/v1/opamp\n\nservice:\n  extensions: [opamp]\n</code></pre> <p>The default configuration template (located at <code>docker/otelcol-configs/config.yaml</code>) shows a complete example with OTLP receivers, OpAMP extension, batch processing, and spanmetrics connector. Your collector will connect to the OpAMP server and receive configuration updates through the TinyOlly UI.</p>"},{"location":"quickstart/","title":"Quick Start","text":"<p>Get TinyOlly running in under 5 minutes!</p>"},{"location":"quickstart/#what-youll-get","title":"What You'll Get","text":"<ul> <li>TinyOlly UI at <code>http://localhost:5005</code></li> <li>OpenTelemetry Collector listening on ports 4317 (gRPC) and 4318 (HTTP)</li> <li>OpAMP Server for remote collector configuration management</li> <li>Demo microservices generating automatic telemetry</li> </ul>"},{"location":"quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker Desktop installed and running</li> <li>Git (to clone the repository)</li> <li>5 minutes of your time</li> </ul>"},{"location":"quickstart/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/tinyolly/tinyolly\ncd tinyolly\n</code></pre>"},{"location":"quickstart/#step-2-start-tinyolly-core","title":"Step 2: Start TinyOlly Core","text":"<pre><code>cd docker\n./01-start-core.sh\n</code></pre> <p>This starts:</p> <ul> <li>OpenTelemetry Collector (ports 4317/4318)</li> <li>OpAMP Server (ports 4320/4321)</li> <li>TinyOlly OTLP Receiver (internal)</li> <li>TinyOlly UI (port 5005)</li> <li>Redis storage (internal)</li> </ul> <p>Wait for the containers to start (~30 seconds).</p>"},{"location":"quickstart/#step-3-deploy-demo-apps-optional-but-recommended","title":"Step 3: Deploy Demo Apps (Optional but Recommended)","text":"<p>In a new terminal:</p> <pre><code>cd docker-demo\n./01-deploy-demo.sh\n</code></pre> <p>This deploys two Flask microservices that automatically generate traffic.</p> <p>Wait 30 seconds for telemetry to appear!</p>"},{"location":"quickstart/#step-4-open-the-ui","title":"Step 4: Open the UI","text":"<p>Open your browser to: <code>http://localhost:5005</code></p> <p>You should see:</p> <p>Trace waterfall with correlated logs and span timing</p>"},{"location":"quickstart/#step-5-explore-the-features","title":"Step 5: Explore the Features","text":""},{"location":"quickstart/#traces-tab","title":"Traces Tab","text":"<p>View distributed traces across microservices with timing waterfall.</p> <p>Span waterfall showing request timing breakdown with correlated logs</p> <p>Click on a span to view detailed JSON data:</p> <p>Span detail view with full OpenTelemetry attributes</p>"},{"location":"quickstart/#logs-tab","title":"Logs Tab","text":"<p>Browse logs with trace/span correlation. Filter by severity (Error, Warn, Info, Debug).</p> <p>Real-time logs with trace and span correlation</p> <p>Click on a log entry to view full details:</p> <p>Log detail view with full attributes and resource info</p> <p>Filter to show only errors:</p> <p>Filtered error logs with trace correlation</p>"},{"location":"quickstart/#metrics-tab","title":"Metrics Tab","text":"<p>Visualize metrics with automatic charting.</p> <p>Time-series metrics visualization with rate charts</p>"},{"location":"quickstart/#service-catalog","title":"Service Catalog","text":"<p>View all services with RED metrics (Rate, Errors, Duration).</p> <p>Service catalog with RED metrics for all services</p>"},{"location":"quickstart/#service-map","title":"Service Map","text":"<p>Visualize service dependencies with an interactive graph.</p> <p>Interactive service dependency map with latency information</p>"},{"location":"quickstart/#opentelemetry-collector-opamp-config","title":"OpenTelemetry Collector + OpAMP Config","text":"<p>View and manage your OpenTelemetry Collector configuration remotely via the OpAMP protocol.</p> <p>OpenTelemetry Collector configuration management via OpAMP</p> <p>This page allows you to:</p> <ul> <li>View current configuration from connected collectors</li> <li>Apply configuration changes with validation and diff preview</li> <li>Use configuration templates for common scenarios (default, prometheus-remote-write, etc.)</li> <li>Check OpAMP server status and see connected collector agents</li> <li>Validate configurations before applying to catch errors early</li> </ul> <p>To use this feature, your OpenTelemetry Collector must be configured with the OpAMP extension (see Docker Deployment or OpenTelemetry Collector documentation).</p>"},{"location":"quickstart/#step-6-use-your-own-application","title":"Step 6: Use Your Own Application","text":"<p>Point your application's OpenTelemetry exporter to:</p> <p>For apps running on your host machine (outside Docker): <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\n</code></pre></p> <p>For apps running inside Docker: <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318\n</code></pre></p> <p>TinyOlly will automatically capture and display your telemetry!</p>"},{"location":"quickstart/#cleanup","title":"Cleanup","text":"<p>Stop demo apps (keeps TinyOlly running): <pre><code>cd docker-demo\n./02-cleanup-demo.sh\n</code></pre></p> <p>Stop everything: <pre><code>cd docker\n./02-stop-core.sh\n</code></pre></p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Configure your own OpenTelemetry Collector</li> <li>Explore the REST API at <code>http://localhost:5005/docs</code></li> <li>Deploy on Kubernetes</li> <li>Learn about the architecture</li> </ul>"},{"location":"quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"quickstart/#ui-shows-no-traceslogsmetrics","title":"UI shows \"No traces/logs/metrics\"","text":"<ul> <li>Wait 30 seconds after starting demo apps</li> <li>Check containers are running: <code>docker ps</code></li> <li>Check demo app logs: <code>docker compose -f docker-demo/docker-compose-demo.yml logs</code></li> </ul>"},{"location":"quickstart/#port-conflicts","title":"Port conflicts","text":"<ul> <li>TinyOlly uses ports 4317, 4318, 4320, 4321, 4343, 5005, 6579</li> <li>Stop conflicting services or modify ports in <code>docker-compose-tinyolly-core.yml</code></li> </ul>"},{"location":"quickstart/#demo-apps-not-generating-traffic","title":"Demo apps not generating traffic","text":"<ul> <li>Restart demo: <code>cd docker-demo &amp;&amp; ./02-cleanup-demo.sh &amp;&amp; ./01-deploy-demo.sh</code></li> <li>Check logs: <code>docker compose -f docker-demo/docker-compose-demo.yml logs demo-frontend</code></li> </ul> <p>For more help, open an issue on GitHub.</p>"},{"location":"technical/","title":"Technical Details","text":"<p>Service dependency map showing service topology</p>"},{"location":"technical/#architecture","title":"Architecture","text":"<pre><code>Demo Frontend  \u2190\u2192  Demo Backend (distributed tracing + auto-traffic)\n        \u2193                    \u2193\n   OTel Collector  \u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2193\n   TinyOlly OTLP Receiver (Async FastAPI, parses OTLP, stores in Redis)\n        \u2193\n   Redis (30-minute TTL with cardinality protection)\n        \u2193\n   TinyOlly UI &amp; REST API (FastAPI + HTML + JavaScript)\n</code></pre>"},{"location":"technical/#data-storage","title":"Data Storage","text":"<ul> <li>Format: Full OpenTelemetry (OTEL) format for traces, logs, and metrics  </li> <li>Redis: All telemetry stored with 30-minute TTL (compressed with ZSTD + msgpack)  </li> <li>Sorted Sets: Time-series data indexed by timestamp  </li> <li>Correlation: Native trace-metric-log correlation via trace/span IDs  </li> <li>Cardinality Protection: Prevents metric explosion  </li> <li>No Persistence: Data vanishes after TTL (ephemeral dev tool)  </li> </ul>"},{"location":"technical/#otlp-compatibility","title":"OTLP Compatibility","text":"<p>TinyOlly is fully OpenTelemetry-native: - Ingestion: Accepts OTLP/gRPC (primary) and OTLP/HTTP - Storage: Stores traces, logs, and metrics in full OTEL format with resources, scopes, and attributes - Correlation: Native support for trace/span ID correlation across all telemetry types - REST API: Exposes OTEL-formatted JSON for programmatic access</p>"}]}