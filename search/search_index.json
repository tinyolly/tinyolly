{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"About TinyOlly","text":"BYOL (Bring Your Own Laptop) Observability Platform for OpenTelemetry"},{"location":"#introducing-tinyolly","title":"Introducing TinyOlly","text":"<p>TinyOlly is located here: https://github.com/tinyolly/tinyolly <pre><code>git clone https://github.com/tinyolly/tinyolly\n</code></pre> Why send telemetry to a cloud observabilty platform while coding? Why not have one on your desktop?  </p> <p>TinyOlly is a lightweight OpenTelemetry-native observability platform built from scratch to visualize and correlate logs, metrics, and traces. No 3rd party observability tools - just Python (FastAPI), Redis, OpenAPI, and JavaScript.</p> <ul> <li>Think of TinyOlly as a development tool to observe and perfect your app's telemetry while in dev </li> <li>Export app metrics, logs, and traces to the Otel collector on Docker or K8S and TinyOlly will visualize and correlate them </li> <li>Try out exotic OpenTelemetry Collector configs in the safety of your own docker/k8s env  </li> <li>Includes a REST API with OpenAPI docs for programmatic access to all telemetry  </li> <li>TinyOlly is not designed to compete with production observability platforms! It is for local development only. It is not focused on infrastructure monitoring at this time.</li> </ul> <p>Platform Support: TinyOlly was built and tested Docker Desktop and Minikube Kubernetes on Apple Silicon Mac but may work on other platforms</p>"},{"location":"#screenshots","title":"Screenshots","text":"Distributed Traces Span Waterfall Real-time Logs Metrics Service Catalog Service Map <p>Built for the OpenTelemetry community</p> <p> GitHub \u2022     Issues </p>"},{"location":"CARDINALITY-PROTECTION/","title":"Cardinality Protection","text":"<p>TinyOlly includes built-in protection against metric cardinality explosion with a configurable limit on unique metric names.</p>"},{"location":"CARDINALITY-PROTECTION/#configuration","title":"Configuration","text":""},{"location":"CARDINALITY-PROTECTION/#environment-variables","title":"Environment Variables","text":"Variable Default Description <code>MAX_METRIC_CARDINALITY</code> 1000 Maximum unique metric names <code>REDIS_TTL</code> 1800 Metric retention (seconds)"},{"location":"CARDINALITY-PROTECTION/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>Update <code>k8s/tinyolly-otlp-receiver.yaml</code>:</p> <pre><code>env:\n  - name: MAX_METRIC_CARDINALITY\n    value: \"2000\"  # Increase limit\n  - name: REDIS_TTL\n    value: \"3600\"  # 1 hour retention\n</code></pre>"},{"location":"CARDINALITY-PROTECTION/#docker-deployment","title":"Docker Deployment","text":"<p>Update <code>docker-compose-tinyolly-core.yml</code> in the <code>docker/</code> directory:</p> <pre><code>environment:\n  MAX_METRIC_CARDINALITY: 2000\n  REDIS_TTL: 3600\n</code></pre>"},{"location":"CARDINALITY-PROTECTION/#monitoring","title":"Monitoring","text":"<p>The UI displays cardinality warnings when approaching the limit: - Yellow Warning: 70-90% of limit reached - Red Alert: 90%+ of limit reached</p> <p>Check current cardinality via the API:</p> <pre><code>curl http://localhost:5005/api/stats\n</code></pre> <p>Response: <pre><code>{\n  \"traces\": 145,\n  \"logs\": 892,\n  \"metrics\": 850,\n  \"metrics_max\": 1000,\n  \"metrics_dropped\": 23\n}\n</code></pre></p>"},{"location":"api/","title":"REST API &amp; OpenAPI","text":"<p>TinyOlly provides a comprehensive REST API for programmatic access to all telemetry data in OpenTelemetry-native format.</p>"},{"location":"api/#interactive-api-documentation","title":"Interactive API Documentation","text":"<p>Access the auto-generated OpenAPI documentation: - Swagger UI: <code>http://localhost:5005/docs</code> - Interactive API explorer - ReDoc: <code>http://localhost:5005/redoc</code> - Alternative documentation - OpenAPI Spec: <code>http://localhost:5005/openapi.json</code> - Machine-readable schema  </p> <p>All APIs return OpenTelemetry-native JSON with: - Resources: <code>service.name</code>, <code>host.name</code>, etc. - Attributes: Metric labels and span attributes - Full Context: Trace/span IDs, timestamps, status codes  </p>"},{"location":"api/#api-endpoints","title":"API Endpoints","text":"<p>The REST API provides endpoints for:</p> <ul> <li>Traces: Retrieve trace data with full span information</li> <li>Logs: Access log entries with trace correlation</li> <li>Metrics: Query metrics with labels and time-series data</li> <li>Stats: Get cardinality and system statistics</li> <li>Services: List all services and their metadata</li> </ul> <p>All endpoints return data in standard OpenTelemetry format, ensuring compatibility with OpenTelemetry tooling and standards.</p>"},{"location":"docker/","title":"Docker Deployment","text":"<p>All examples are launched from the repo - clone it first or download the current GitHub release archive: <pre><code>git clone https://github.com/tinyolly/tinyolly\n</code></pre></p>"},{"location":"docker/#1-deploy-tinyolly-core-required","title":"1. Deploy TinyOlly Core (Required)","text":"<p>Start the observability backend (OTel Collector, TinyOlly Receiver, Redis, UI):</p> <pre><code>cd docker\n./01-start-core.sh\n</code></pre> <p>This starts: - OTel Collector: Listening on <code>localhost:4317</code> (gRPC) and <code>localhost:4318</code> (HTTP) - TinyOlly UI: <code>http://localhost:5005</code> - TinyOlly OTLP Receiver and its Redis storage: OTLP observability back end and storage - Rebuilds images if code changes are detected  </p> <p>Open the UI: <code>http://localhost:5005</code> (empty until you send data)</p> <p>Stop core services: <pre><code>./02-stop-core.sh\n</code></pre></p>"},{"location":"docker/#2-deploy-demo-apps-optional","title":"2. Deploy Demo Apps (Optional)","text":"<p>Deploy two Flask microservices with automatic traffic generation:</p> <pre><code>cd docker-demo\n./01-deploy-demo.sh\n</code></pre> <p>Wait 30 seconds. The demo apps automatically generate traffic - traces, logs, and metrics will appear in the UI!</p> <p>Stop demo apps: <pre><code>./02-cleanup-demo.sh\n</code></pre></p> <p>This leaves TinyOlly core running. To stop everything: <pre><code>cd docker\n./02-stop-core.sh\n</code></pre></p>"},{"location":"docker/#3-opentelemetry-demo-20-services-optional","title":"3. OpenTelemetry Demo (~20 Services - Optional)","text":"<p>Prerequisites: Clone the OpenTelemetry Demo first: <pre><code>git clone https://github.com/open-telemetry/opentelemetry-demo\ncd opentelemetry-demo\n</code></pre></p> <p>Configure: Edit <code>src/otel-collector/otelcol-config-extras.yml</code>: <pre><code>exporters:\n  otlphttp/tinyolly:\n    endpoint: http://otel-collector:4318\n\nservice:\n  pipelines:\n    traces:\n      exporters: [spanmetrics, otlphttp/tinyolly]\n</code></pre></p> <p>Deploy: <pre><code>export OTEL_COLLECTOR_HOST=host.docker.internal\ndocker compose up \\\n  --scale otel-collector=0 \\\n  --scale prometheus=0 \\\n  --scale grafana=0 \\\n  --scale jaeger=0 \\\n  --scale opensearch=0 \\\n  --force-recreate \\\n  --remove-orphans \\\n  --detach\n</code></pre></p> <p>Stop: <pre><code>docker compose down\n</code></pre></p> <p>Note</p> <p>This disables the demo's built-in collector, Jaeger, OpenSearch, Grafana, and Prometheus. All telemetry routes to Otel Collector -&gt; TinyOlly.</p>"},{"location":"docker/#4-use-tinyolly-with-your-own-apps","title":"4. Use TinyOlly with Your Own Apps","text":"<p>After deploying TinyOlly core (step 1 above), instrument your application to send telemetry:</p> <p>For apps running in Docker containers: Point your OpenTelemetry exporter to: - gRPC: <code>http://otel-collector:4317</code> - HTTP: <code>http://otel-collector:4318</code> </p> <p>For apps running on your host machine (outside Docker): Docker Desktop automatically exposes container ports to <code>localhost</code>. Point your OpenTelemetry exporter to: - gRPC: <code>http://localhost:4317</code> - HTTP: <code>http://localhost:4318</code> </p> <p>Example environment variables: <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\n</code></pre></p> <p>The Otel Collector will forward everything to TinyOlly's OTLP receiver, which process telemetry and stores it in Redis in OTEL format for the backend and UI to access.</p>"},{"location":"docker/#5-tinyolly-core-only-deployment-use-your-own-docker-opentelemetry-collector","title":"5. TinyOlly Core-Only Deployment: Use Your Own Docker OpenTelemetry Collector","text":"<p>If you already have an OpenTelemetry Collector or want to send telemetry directly to the TinyOlly Receiver, you can deploy the core components without the bundled OTel Collector.</p> <pre><code>cd docker-core-only\ndocker compose -f docker-compose-tinyolly-core.yml up -d\n</code></pre> <p>This starts: - TinyOlly OTLP Receiver: Listening on <code>localhost:4343</code> (gRPC) - TinyOlly UI: <code>http://localhost:5005</code> - TinyOlly Redis: <code>localhost:6579</code></p> <p>Swap out the included Otel Collector for any distro of Otel Collector.</p> <p>Point your OpenTelemetry exporters to tinyolly-otlp-receiver:4343: i.e. <pre><code>exporters:\n  debug:\n    verbosity: detailed\n\n  otlp:\n    endpoint: \"tinyolly-otlp-receiver:4343\"\n    tls:\n      insecure: true\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, otlp, spanmetrics]\n\n    metrics:\n      receivers: [otlp,spanmetrics]\n      processors: [batch]\n      exporters: [debug, otlp]\n\n    logs:\n      receivers: [otlp]\n      processors: [batch]\n      exporters: [debug, otlp]\n</code></pre></p> <p>The Otel Collector will forward everything to TinyOlly's OTLP receiver, which process telemetry and stores it in Redis in OTEL format for the backend and UI to access.</p>"},{"location":"kubernetes/","title":"Kubernetes Deployment","text":"<p>All examples are launched from the repo - clone it first or download the current GitHub release archive: <pre><code>git clone https://github.com/tinyolly/tinyolly\n</code></pre></p>"},{"location":"kubernetes/#prerequisites","title":"Prerequisites","text":"<ul> <li>Minikube</li> <li>kubectl</li> </ul>"},{"location":"kubernetes/#1-deploy-tinyolly-core","title":"1. Deploy TinyOlly Core","text":"<ol> <li> <p>Start Minikube:</p> <pre><code>minikube start\n</code></pre> </li> <li> <p>Build Images:</p> <p>Run the build script to build the Docker images inside Minikube's Docker daemon:</p> <pre><code>./k8s/01-build-images.sh\n</code></pre> </li> <li> <p>Apply Manifests:</p> <p>Apply the Kubernetes manifests to deploy the services:</p> <pre><code>kubectl apply -f k8s/\n</code></pre> </li> <li> <p>Access the UI:</p> <p>To access the TinyOlly UI (Service Type: LoadBalancer) on macOS with Minikube, you need to use <code>minikube tunnel</code>.</p> <p>Open a new terminal window and run:</p> <pre><code>minikube tunnel\n</code></pre> <p>You may be asked for your password. Keep this terminal open.</p> <p>Now you can access the TinyOlly UI at: http://localhost:5002</p> </li> <li> <p>Send Telemetry from Host Apps:</p> <p>To send telemetry from applications running on your host machine (outside Kubernetes), use <code>kubectl port-forward</code> to expose the OTel Collector ports:</p> <p>Open a new terminal window and run:</p> <pre><code>kubectl port-forward service/otel-collector 4317:4317 4318:4318\n</code></pre> <p>Keep this terminal open. Now point your application's OpenTelemetry exporter to: - gRPC: <code>http://localhost:4317</code> - HTTP: <code>http://localhost:4318</code> </p> <p>Example environment variables: <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\n</code></pre></p> <p>For apps running inside the Kubernetes cluster: Use the Kubernetes service name: - gRPC: <code>http://otel-collector:4317</code> - HTTP: <code>http://otel-collector:4318</code> </p> </li> <li> <p>Clean Up:</p> <p>Use the cleanup script to remove all TinyOlly resources:</p> <pre><code>./k8s/01-cleanup.sh\n</code></pre> <p>Shut down Minikube: <pre><code>minikube stop\n</code></pre></p> <p>Minikube may be more stable if you delete it: <pre><code>minikube delete\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/#2-demo-applications-optional","title":"2. Demo Applications (Optional)","text":"<p>To see TinyOlly in action with instrumented microservices:</p> <pre><code>cd k8s-demo\n./01-deploy.sh\n</code></pre> <p>To clean up the demo: <pre><code>./02-cleanup.sh\n</code></pre></p> <p>The demo includes two microservices that automatically generate traffic, showcasing distributed tracing across service boundaries.</p>"},{"location":"kubernetes/#3-opentelemetry-demo-20-services-optional","title":"3. OpenTelemetry Demo (~20 Services - Optional)","text":"<p>To deploy the full OpenTelemetry Demo with ~20 microservices:</p> <p>Prerequisites: - TinyOlly must be deployed first (see Setup above) - Helm installed - Sufficient cluster resources (demo is resource-intensive)  </p> <p>Deploy: <pre><code>cd k8s-otel-demo\n./01-deploy-otel-demo-helm.sh\n</code></pre></p> <p>This deploys all OpenTelemetry Demo services configured to send telemetry to TinyOlly's collector via HTTP on port 4318. Built-in observability tools (Jaeger, Grafana, Prometheus) are disabled.</p> <p>Cleanup: <pre><code>cd k8s-otel-demo\n./02-cleanup-otel-demo-helm.sh\n</code></pre></p> <p>This removes the OpenTelemetry Demo but leaves TinyOlly running.</p>"},{"location":"kubernetes/#4-tinyolly-core-only-deployment-use-your-own-kubernetes-opentelemetry-collector","title":"4. TinyOlly Core-Only Deployment: Use Your Own Kubernetes OpenTelemetry Collector","text":"<p>To deploy TinyOlly without the bundled OTel Collector (e.g., if you have an existing collector daemonset):</p> <ol> <li> <p>Build Images: <pre><code>./k8s/01-build-images.sh\n</code></pre></p> </li> <li> <p>Deploy Core: <pre><code>cd k8s-core-only\n./deploy.sh\n</code></pre></p> </li> <li> <p>Access UI:     Run <code>minikube tunnel</code> and access <code>http://localhost:5002</code>.</p> </li> <li> <p>Cleanup: <pre><code>./cleanup.sh\n</code></pre></p> </li> </ol>"},{"location":"licensing/","title":"Licensing","text":"<p>TinyOlly is released under the BSD 3-Clause License. The full license text is available in the LICENSE file. This license permits free use, modification, and redistribution for individuals, researchers, and small organizations.</p>"},{"location":"licensing/#community-and-small-scale-use","title":"Community and Small-Scale Use","text":"<p>TinyOlly may be used freely under the BSD license for:</p> <ul> <li>Individual developers and hobby projects  </li> <li>Academic and research use  </li> <li>Startups or small organizations  </li> <li>Limited internal development, tooling, experimentation, or evaluation  </li> </ul> <p>No additional agreements are required for these scenarios.</p>"},{"location":"licensing/#commercial-and-large-scale-use","title":"Commercial and Large-Scale Use","text":"<p>Organizations deploying TinyOlly in a broader or more intensive capacity are required to obtain a commercial license. This includes use cases such as:</p> <ul> <li>Organizations with approximately 50 or more employees  </li> <li>Deployments across multiple engineering teams  </li> <li>Production or mission-critical observability workflows  </li> <li>Integration into commercial software, platforms, or SaaS products  </li> <li>High-volume or distributed environments</li> </ul> <p>For commercial licensing inquiries, contact:  </p>"},{"location":"licensing/#rationale","title":"Rationale","text":"<p>This model ensures that TinyOlly remains fully open source and accessible to the community while providing a sustainable path for supporting organizations that rely on it at scale.</p>"},{"location":"otel-collector/","title":"OpenTelemetry Collector","text":"<p>TinyOlly uses the OpenTelemetry Collector as the telemetry ingestion and shipping layer. The collector receives telemetry from your applications and forwards it to TinyOlly's OTLP receiver.</p>"},{"location":"otel-collector/#configuration","title":"Configuration","text":"<p>TinyOlly includes a sample collector configuration that you can customize for your needs. The configuration files are located at:</p> <ul> <li>Docker: <code>docker/otel-collector-config.yaml</code></li> <li>Kubernetes: <code>k8s/otel-collector-config.yaml</code></li> </ul>"},{"location":"otel-collector/#default-configuration","title":"Default Configuration","text":"<p>The default configuration includes:</p> <ul> <li>OTLP Receivers: Accepts telemetry on ports 4317 (gRPC) and 4318 (HTTP)</li> <li>Span Metrics Connector: Automatically generates RED metrics from traces</li> <li>Batch Processor: Batches telemetry for efficient processing</li> <li>OTLP Exporter: Forwards all telemetry to TinyOlly's OTLP receiver</li> </ul>"},{"location":"otel-collector/#customization-examples","title":"Customization Examples","text":"<p>You can extend the collector configuration to add additional capabilities. The collector uses the <code>otel/opentelemetry-collector-contrib</code> image which includes:</p> <ul> <li>Receivers: OTLP, Prometheus, Jaeger, Zipkin, and many more</li> <li>Processors: Batch, Memory Limiter, Resource Detection, Tail Sampling, Filtering</li> <li>Connectors: Span Metrics, Service Graph</li> <li>Exporters: OTLP, Prometheus, Logging, and many more</li> </ul> <p>For a complete list of available components, see the OpenTelemetry Collector Contrib documentation.</p>"},{"location":"otel-collector/#applying-changes","title":"Applying Changes","text":""},{"location":"otel-collector/#docker","title":"Docker","text":"<p>After modifying <code>docker/otel-collector-config.yaml</code> rebuild/restart using: <pre><code>cd docker\n./01-start-core.sh\n</code></pre></p>"},{"location":"otel-collector/#kubernetes","title":"Kubernetes","text":"<p>After modifying <code>k8s/otel-collector-config.yaml</code>: rebuild/restart using: <pre><code>kubectl apply -f k8s/otel-collector-config.yaml\nkubectl rollout restart deployment/otel-collector\n</code></pre></p>"},{"location":"technical/","title":"Technical Details","text":""},{"location":"technical/#architecture","title":"Architecture","text":"<pre><code>Demo Frontend  \u2190\u2192  Demo Backend (distributed tracing + auto-traffic)\n        \u2193                    \u2193\n   OTel Collector  \u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2193\n   TinyOlly OTLP Receiver (Async FastAPI, parses OTLP, stores in Redis)\n        \u2193\n   Redis (30-minute TTL with cardinality protection)\n        \u2193\n   TinyOlly UI &amp; REST API (FastAPI + HTML + JavaScript)\n</code></pre>"},{"location":"technical/#data-storage","title":"Data Storage","text":"<ul> <li>Format: Full OpenTelemetry (OTEL) format for traces, logs, and metrics  </li> <li>Redis: All telemetry stored with 30-minute TTL (compressed with ZSTD + msgpack)  </li> <li>Sorted Sets: Time-series data indexed by timestamp  </li> <li>Correlation: Native trace-metric-log correlation via trace/span IDs  </li> <li>Cardinality Protection: Prevents metric explosion  </li> <li>No Persistence: Data vanishes after TTL (ephemeral dev tool)  </li> </ul>"},{"location":"technical/#otlp-compatibility","title":"OTLP Compatibility","text":"<p>TinyOlly is fully OpenTelemetry-native: - Ingestion: Accepts OTLP/gRPC (primary) and OTLP/HTTP - Storage: Stores traces, logs, and metrics in full OTEL format with resources, scopes, and attributes - Correlation: Native support for trace/span ID correlation across all telemetry types - REST API: Exposes OTEL-formatted JSON for programmatic access</p>"}]}